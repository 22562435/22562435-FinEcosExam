---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Question 3: Portfolio Construction"
#subtitle: "Hyperbolic discounting in new car purchases"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Liam Andrew Beattie"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Financial Econometrics 871, Stellenbosch University, South Africa" # First Author's Affiliation
Email1: "22562435\\@sun.ac.za" # First Author's Email address

# Author2: "Abdul Qaadir Cassiem"
# #Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "20863667\\@sun.ac.za"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"

#CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: FALSE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
header-includes:
#   - \usepackage{lscape}
#   - \usepackage{colortbl} # Add additional packages here.
#   - \setlength{\parskip}{0pt}      # Set the space between paragraphs to 0pt
#   - \setlength{\parindent}{1em}      # Set the indent size for the first line of paragraphs (adjust as needed)

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: 
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!
rm(list = ls())
# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
source("code/install_and_load.R")
install_and_load(c("tidyverse","zoo","ggplot2","PerformanceAnalytics","lubridate","ggExtra","xts"))

list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

ALSI <- read_rds("data/ALSI.rds")
ALSI$date <- as.Date(ALSI$date)
RebDays <- read_rds("data/Rebalance_days.rds")
Zar<-read_rds("data/Monthly_zar.rds")

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}



```{r}
Zar<- Zar %>% categorize_currency( value)

# View the modified dataset
```


To analyze the relationship between currency performance/volatility and the return profiles of the ALSI and SWIX methodologies, you need to design a systematic approach to combine and investigate these data. Below is a high-level plan for how you should proceed:

---

### **1. Understand the Key Relationships**
Before diving into the analysis, understand the key relationships in the prompt:
   - **Currency Performance (`Zar$value`)**: This likely reflects the USD/ZAR exchange rate. Changes in this rate could affect sectoral returns, particularly for export-driven sectors (like Resources) or import-heavy sectors.
   - **Volatility (`Zar$volatility`)**: This categorization ("Normal Volatility," etc.) provides a way to segment time periods based on currency market conditions.
   - **Sectoral and Index Returns (`ALSI` and `SWIX`)**: Analyze sectoral and index return data across "Resources," "Financials," etc., to identify how different weighting methodologies (ALSI vs. SWIX) perform under varying currency environments.

---

### **2. Integrate Data**
You need to align the `Zar` data (currency data) with the `ALSI` and `SWIX` data:
   - **Common Time Dimension**: Ensure all datasets are aligned by `date`. You may need to merge `Zar` with the `ALSI` and `SWIX` datasets on the `date` column.
   - **Sector or Index Aggregation**: Summarize the ALSI and SWIX returns by sector or index size to reduce complexity if necessary.

---

### **3. Define Key Metrics**
Determine what metrics you need to calculate and analyze:
   - **Currency Change**: Compute monthly percentage changes in `Zar$value`:
     \[
     \text{Currency Change (\%)} = \frac{\text{ZAR}_t - \text{ZAR}_{t-1}}{\text{ZAR}_{t-1}}
     \]
   - **Volatility Binning**: Categorize periods into different volatility regimes using `Zar$volatility`.
   - **Return Profiles**:
     - For each sector/index, calculate monthly returns (if not already in the data).
     - Compare cumulative returns under ALSI and SWIX methodologies during different volatility regimes and currency performance periods.

---

### **4. Segment and Compare Returns**
Analyze the return profiles across different scenarios:
   1. **Currency Performance**:
      - Separate periods of currency strength (appreciation) vs. weakness (depreciation).
      - Compare returns for sectors and index methodologies (ALSI vs. SWIX) during these periods.
   2. **Volatility Regimes**:
      - Examine the performance of sectors/indexes under "High Volatility" vs. "Normal Volatility."
      - Look for sector-specific patterns. For instance, Resources may perform well during currency weakness due to their export-driven nature.
   3. **Combined Analysis**:
      - Analyze returns for combinations of currency performance and volatility (e.g., "Weak Currency & High Volatility").

---

### **5. Visualization and Interpretation**
Use visualizations to uncover trends:
   - **Line Plots**: Compare cumulative returns for ALSI and SWIX methodologies over time, segmented by sector or index size.
   - **Facet Plots**: Create faceted line plots with panels for different volatility regimes or currency performance levels.
   - **Bar Plots**: Show average returns for ALSI and SWIX during specific scenarios (e.g., "Weak Currency & High Volatility").

---

### **6. Summary Insights**
From your findings, answer:
   - How do ALSI and SWIX return profiles differ under various currency performance and volatility conditions?
   - Which sectors are most sensitive to currency movements or volatility, and how do methodologies amplify or mitigate this sensitivity?

---

If this general approach aligns with your objective, let me know, and Iâ€™ll help craft the R code for the individual steps!


```{r}

# Assuming ALSI is your data frame
# Convert date to Date type if not already


# Calculate average returns by size and sector
summary_data <- ALSI %>%
  group_by(Sector, Tickers) %>%
  summarise(
    ALSI_Return = gm_mean(J203, na.rm = TRUE),
    SWIX_Return = gm_mean(J403, na.rm = TRUE)
  ) %>%
  ungroup()
```



```{r}
library(ggplot2)

# Create a new column for size classification
summary_data <- summary_data %>%
  mutate(Size = case_when(
    str_detect(Tickers, "L") ~ "Large Caps",
    str_detect(Tickers, "M") ~ "Mid Caps",
    TRUE ~ "Small Caps"
  ))

# Plotting
ggplot(summary_data, aes(x = Size, fill = Sector)) +
  geom_bar(aes(y = ALSI_Return), position = "dodge", stat = "identity",alpha=0.5) +
  geom_bar(aes(y = SWIX_Return), position = "dodge", stat = "identity", alpha = 0.5) +
  labs(title = "Average Returns by Size and Sector",
       y = "Average Returns",
       fill = "Sector") +
  scale_fill_brewer(palette = "Set1") +
  fmxdat::theme_fmx()
```


```{r}
# Calculate sector returns over time
sector_time_data <- ALSI %>%
  group_by(date, Sector) %>%
  summarise(
    ALSI_Return = sum(J203, na.rm = TRUE),
    SWIX_Return = sum(J403, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = c(ALSI_Return, SWIX_Return), names_to = "Index", values_to = "Return")

# Plotting
ggplot(sector_time_data, aes(x = date, y = Return, fill = Sector)) +
  geom_area(position = "fill") +
  facet_wrap(~ Index,ncol=1) +
  labs(title = "Sector Exposure Over Time",
       y = "Proportion of Returns",
       fill = "Sector") +
  fmxdat::theme_fmx() +
  scale_fill_brewer(palette = "Set2")
```



```{r}
evaluate_capped_index(ALSI, RebDays, capping_levels = c(0.05, 0.10, Inf),top_n = 100)

```

```{r}
evaluate_capped_index(ALSI, RebDays, capping_levels = c(0.05, 0.10, Inf), SWIX = TRUE,top_n = 100)

```



















```{r}
# Calculate cumulative returns for top N stocks
top_n_stocks <- ALSI %>%
  group_by(date) %>%
  arrange(desc(J203)) %>%
  slice(1:10) %>%
  summarise(Total_ALSI_Return = sum(J203))

# Plotting
ggplot(top_n_stocks, aes(x = date, y = Total_ALSI_Return)) +
  geom_line(color = "blue") +
  labs(title = "Cumulative Returns of Top N Stocks (ALSI)",
       y = "Cumulative Returns") +
  theme_minimal()
```


